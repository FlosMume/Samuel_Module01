{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **MCP Homework and Local LLM Implementation with Ollama & LangChain**\n",
    "*In this thrust we have four tasks, which will be enhancing MCP using and learning how to use two brilliant tools for LLM application.*\n",
    "\n",
    "Prework:  follow the instruction in slides.Implement the MCP in Local Environment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1 Using MCP to built Agent-like work-flow.\n",
    "\n",
    "**Task 1.1 MCP + Claude = Browser Automation**\\\n",
    "*use MCP + Claude to do browser automation tasks*\n",
    "step 1: Learn all kinds of cool MCP server\\\n",
    "[Introducing to more MCP server](https://github.com/punkpeye/awesome-mcp-servers)\n",
    "\n",
    "step 2: Install cline\\\n",
    "[cline](https://cline.bot/)\n",
    "\n",
    "step 3: Open Claude, follow the instruction in the MCP Configuration file(mcp_example.json). Use Brave Search„ÄÅGitHub„ÄÅPuppeteer„ÄÅFilesystem„ÄÅSequential Thinking and Notion.\n",
    "\n",
    "Now, follow the instructions below to complete a small task for each plugin.\n",
    "\n",
    "1. üîç Use Brave Search to:\n",
    "Task: Search for ‚Äúlatest AI paper publication platforms‚Äù and list the top 3 search results with titles and URLs.\n",
    "Prompt in Claude:\n",
    "\"Use Brave Search to look up the latest AI paper publication platforms and return the top 3 results with title and link.\"\n",
    "\n",
    "2. üíº Use GitHub to:\n",
    "Task: Access one of your public repositories (e.g., my-cool-project) and list the 5 most recent commits.\n",
    "Prompt in Claude:\n",
    "\"Connect to my GitHub account using the MCP plugin and list the 5 latest commits from the repository my-cool-project.\"\n",
    "\n",
    "3. ü§ñ Use Puppeteer to:\n",
    "Task: Visit https://www.inference.ai/, take a full-page screenshot, and save it as example.png.\n",
    "Prompt in Claude:\n",
    "\"Use Puppeteer to go to https://www.inference.ai/ and capture a full-page screenshot saved as example.png.\"\n",
    "\n",
    "4. üíæ Use Filesystem to:\n",
    "Task: Create a new folder on your Desktop named mcp_test, and inside it, create a text file hello.txt containing ‚ÄúHello MCP!‚Äù.\n",
    "Prompt in Claude:\n",
    "\"Use Filesystem to create a folder named mcp_test on my Desktop and add a file hello.txt inside with the text 'Hello MCP!'.\"\n",
    "\n",
    "5. üß† Use Sequential Thinking to:\n",
    "Task: Think step-by-step about how to prepare for a technical interview and generate a preparation plan.\n",
    "Prompt in Claude:\n",
    "\"Use Sequential Thinking to create a step-by-step plan for preparing for a technical interview.\"\n",
    "\n",
    "6. üìù Use Notion to:\n",
    "Task: Create a new Notion page titled ‚ÄúMCP Automation Test‚Äù and log the results of all the tasks above.\n",
    "Prompt in Claude:\n",
    "\"Use the Notion plugin to create a new page titled 'MCP Automation Test' and write a summary of the tasks I just completed using each plugin.\"\n",
    "\n",
    "\n",
    "Advanced Task: Use Claude + Puppeteer to automatically visit a webpage, scrape table content, and save it locally (with the help of the Filesystem plugin).\n",
    "Project Management Workflow: Record the scraped and analyzed data into a Notion database, automatically generating documentation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">**For Part1, especially step 3, refer to the seperate files: \"Task 1dot1 MCP + Claude = Browser Automation F\" and \"Advanced Task\" -- Samuel**.</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2 Play with Ollama\n",
    "\n",
    "<img src=\"https://ollama.com/public/blog/meta-ollama-llama3.png\" alt=\"jupyter\" width=\"500\"/>\n",
    "\n",
    "***Ollama** is a **convenient** and **free** frameworkÔºådesigned for easy deployment and running of large language models (LLMs) locally.*  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "**Task 2.1: Install Ollama and run LLMs locally**  \n",
    "- refer to [Ollama](https://ollama.ai/) to complete installation.  \n",
    "- Run `ollama run llama2` from the command line to download and launch the `llama2` model.\n",
    "\n",
    "\n",
    "**Task 2.2: Using Ollama to call OpenAI API**\\\n",
    "*Ollama now has built-in compatibility with the OpenAI Chat Completions API, making it possible to use more tooling and applications with Ollama locally.*\n",
    "\n",
    "See official instruction belowÔºö\\\n",
    "[Ollama OpenAI Compatibility](https://ollama.com/blog/openai-compatibility)\\\n",
    "[Ollama OpenAI](https://github.com/ollama/ollama/blob/main/docs/openai.md)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "UsageÔºö"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*To invoke Ollama‚Äôs OpenAI compatible API endpoint, use the same OpenAI format and change the hostname to http://localhost:11434:*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Curl Method:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "curl http://localhost:11434/v1/chat/completions \\\n",
    "    -H \"Content-Type: application/json\" \\\n",
    "    -d '{\n",
    "        \"model\": \"llama2\",\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"You are a helpful assistant.\"\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": \"Hello!\"\n",
    "            }\n",
    "        ]\n",
    "    }'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OpenAI Python library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 2020 World Series was played at the Globe Life Field in Arlington, Texas. The Los Angeles Dodgers defeated the Tampa Bay Rays in the series, winning four games to none.\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(\n",
    "    base_url = 'http://localhost:11434/v1',\n",
    "    api_key='ollama', # required, but unused\n",
    ")\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "  model=\"llama2\",\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Who won the world series in 2020?\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"The LA Dodgers won in 2020.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Where was it played?\"}\n",
    "  ]\n",
    ")\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*In above examples, ‚ÄúOllama‚Äù is essentially acting as a local server that is compatible with the OpenAI API. In other words, the endpoint you‚Äôre calling‚Äîwhether via code or a cURL command‚Äîis not the official OpenAI endpoint at https://api.openai.com/v1/ but rather http://localhost:11434/v1/. The local process running on this port is Ollama.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 3 Combining LangChain with Ollama‚Äôs local LLMs\n",
    "\n",
    "*LangChain simplifies every stage of the LLM application lifecycle.\n",
    "It unifies functional modules such as \"Prompt design\", \"Multi-round dialogue memory (Memory)\", \"External data retrieval (Retrieval)\" and \"Tools/Agents\" into a unified package. In this way, you do not need to manually manage each step of the language model call and data flow, and only need to focus on business logic.*\n",
    "\n",
    "LangChain‚ÄìOllama Documentation: [https://python.langchain.com/docs/integrations/llms/ollama](https://python.langchain.com/docs/integrations/llms/ollama)  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<img src=\"https://miro.medium.com/v2/resize:fit:4800/format:webp/1*-PlFCd_VBcALKReO3ZaOEg.png\" alt=\"jupyter\" width=\"700\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 3.1 Reproduce practice in lecture using LCEL**\n",
    "\n",
    "*A chain is a sequence of steps or model calls connected together to achieve a larger task. Each step can involve retrieving information, transforming text, or invoking a language model in some way, and then passing its output on to the next step in the chain. This structure helps you build more complex workflows or pipelines using multiple actions in a simple, organized manner.*\n",
    "\n",
    "- what is LCEL? LCEL is a much simpler way to construct \"Chain\"\\\n",
    "[LCEL](https://python.langchain.com/docs/concepts/lcel/)\\\n",
    "why use it?\\\n",
    "[Why LCEL](https://python.langchain.com/v0.1/docs/expression_language/why/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain-core\n",
      "  Downloading langchain_core-0.3.72-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting langsmith>=0.3.45 (from langchain-core)\n",
      "  Downloading langsmith-0.4.8-py3-none-any.whl.metadata (15 kB)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in c:\\users\\ch939\\anaconda3\\lib\\site-packages (from langchain-core) (8.2.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\ch939\\anaconda3\\lib\\site-packages (from langchain-core) (1.33)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\ch939\\anaconda3\\lib\\site-packages (from langchain-core) (6.0.1)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in c:\\users\\ch939\\anaconda3\\lib\\site-packages (from langchain-core) (4.11.0)\n",
      "Requirement already satisfied: packaging>=23.2 in c:\\users\\ch939\\anaconda3\\lib\\site-packages (from langchain-core) (23.2)\n",
      "Collecting pydantic>=2.7.4 (from langchain-core)\n",
      "  Downloading pydantic-2.11.7-py3-none-any.whl.metadata (67 kB)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\ch939\\anaconda3\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core) (2.1)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\ch939\\anaconda3\\lib\\site-packages (from langsmith>=0.3.45->langchain-core) (0.27.0)\n",
      "Collecting orjson<4.0.0,>=3.9.14 (from langsmith>=0.3.45->langchain-core)\n",
      "  Downloading orjson-3.11.1-cp312-cp312-win_amd64.whl.metadata (43 kB)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\ch939\\anaconda3\\lib\\site-packages (from langsmith>=0.3.45->langchain-core) (2.32.2)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\users\\ch939\\anaconda3\\lib\\site-packages (from langsmith>=0.3.45->langchain-core) (1.0.0)\n",
      "Collecting zstandard<0.24.0,>=0.23.0 (from langsmith>=0.3.45->langchain-core)\n",
      "  Downloading zstandard-0.23.0-cp312-cp312-win_amd64.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\ch939\\anaconda3\\lib\\site-packages (from pydantic>=2.7.4->langchain-core) (0.6.0)\n",
      "Collecting pydantic-core==2.33.2 (from pydantic>=2.7.4->langchain-core)\n",
      "  Downloading pydantic_core-2.33.2-cp312-cp312-win_amd64.whl.metadata (6.9 kB)\n",
      "Collecting typing-extensions>=4.7 (from langchain-core)\n",
      "  Downloading typing_extensions-4.14.1-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting typing-inspection>=0.4.0 (from pydantic>=2.7.4->langchain-core)\n",
      "  Downloading typing_inspection-0.4.1-py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: anyio in c:\\users\\ch939\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core) (4.2.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\ch939\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core) (2025.4.26)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\ch939\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core) (1.0.2)\n",
      "Requirement already satisfied: idna in c:\\users\\ch939\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core) (3.7)\n",
      "Requirement already satisfied: sniffio in c:\\users\\ch939\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core) (1.3.0)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\ch939\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core) (0.14.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\ch939\\anaconda3\\lib\\site-packages (from requests<3,>=2->langsmith>=0.3.45->langchain-core) (2.0.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\ch939\\anaconda3\\lib\\site-packages (from requests<3,>=2->langsmith>=0.3.45->langchain-core) (2.2.2)\n",
      "Downloading langchain_core-0.3.72-py3-none-any.whl (442 kB)\n",
      "Downloading langsmith-0.4.8-py3-none-any.whl (367 kB)\n",
      "Downloading pydantic-2.11.7-py3-none-any.whl (444 kB)\n",
      "Downloading pydantic_core-2.33.2-cp312-cp312-win_amd64.whl (2.0 MB)\n",
      "   ---------------------------------------- 0.0/2.0 MB ? eta -:--:--\n",
      "   ---------- ----------------------------- 0.5/2.0 MB 3.4 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 1.3/2.0 MB 3.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.0/2.0 MB 3.6 MB/s eta 0:00:00\n",
      "Downloading typing_extensions-4.14.1-py3-none-any.whl (43 kB)\n",
      "Downloading orjson-3.11.1-cp312-cp312-win_amd64.whl (131 kB)\n",
      "Downloading typing_inspection-0.4.1-py3-none-any.whl (14 kB)\n",
      "Downloading zstandard-0.23.0-cp312-cp312-win_amd64.whl (495 kB)\n",
      "Installing collected packages: zstandard, typing-extensions, orjson, typing-inspection, pydantic-core, pydantic, langsmith, langchain-core\n",
      "  Attempting uninstall: zstandard\n",
      "    Found existing installation: zstandard 0.22.0\n",
      "    Uninstalling zstandard-0.22.0:\n",
      "      Successfully uninstalled zstandard-0.22.0\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing_extensions 4.11.0\n",
      "    Uninstalling typing_extensions-4.11.0:\n",
      "      Successfully uninstalled typing_extensions-4.11.0\n",
      "  Attempting uninstall: pydantic-core\n",
      "    Found existing installation: pydantic_core 2.14.6\n",
      "    Uninstalling pydantic_core-2.14.6:\n",
      "      Successfully uninstalled pydantic_core-2.14.6\n",
      "  Attempting uninstall: pydantic\n",
      "    Found existing installation: pydantic 2.5.3\n",
      "    Uninstalling pydantic-2.5.3:\n",
      "      Successfully uninstalled pydantic-2.5.3\n",
      "Successfully installed langchain-core-0.3.72 langsmith-0.4.8 orjson-3.11.1 pydantic-2.11.7 pydantic-core-2.33.2 typing-extensions-4.14.1 typing-inspection-0.4.1 zstandard-0.23.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tensorflow-intel 2.18.0 requires ml-dtypes<0.5.0,>=0.4.0, but you have ml-dtypes 0.5.1 which is incompatible.\n",
      "tensorflow-intel 2.18.0 requires tensorboard<2.19,>=2.18, but you have tensorboard 2.19.0 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "# install langchain-core\n",
    "%pip install --upgrade langchain-core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: langchain-core\n",
      "Version: 0.3.72\n",
      "Summary: Building applications with LLMs through composability\n",
      "Home-page: \n",
      "Author: \n",
      "Author-email: \n",
      "License: MIT\n",
      "Location: C:\\Users\\ch939\\anaconda3\\Lib\\site-packages\n",
      "Requires: jsonpatch, langsmith, packaging, pydantic, PyYAML, tenacity, typing-extensions\n",
      "Required-by: \n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Verify Installation\n",
    "%pip show langchain-core"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example code with a Ollama local modelÔºö"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "langchain_core is installed and accessible.\n"
     ]
    }
   ],
   "source": [
    "# Check if langchain-core is installed or recognized by Jupyter kernel\n",
    "try:\n",
    "    import langchain_core\n",
    "    print(\"langchain_core is installed and accessible.\")\n",
    "except ImportError as e:\n",
    "    print(f\"Error importing langchain_core: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ch939\\anaconda3\\python.exe\n"
     ]
    }
   ],
   "source": [
    "# show the path to the Python executable that the current kernel is using.\n",
    "import sys\n",
    "print(sys.executable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: pydantic 2.11.7\n",
      "Uninstalling pydantic-2.11.7:\n",
      "  Successfully uninstalled pydantic-2.11.7\n",
      "Found existing installation: pydantic_core 2.33.2\n",
      "Uninstalling pydantic_core-2.33.2:\n",
      "  Successfully uninstalled pydantic_core-2.33.2\n",
      "Found existing installation: langchain-core 0.3.72\n",
      "Uninstalling langchain-core-0.3.72:\n",
      "  Successfully uninstalled langchain-core-0.3.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Skipping langchain-community as it is not installed.\n",
      "WARNING: Skipping langchain as it is not installed.\n"
     ]
    }
   ],
   "source": [
    "# Uninstall potentially conflicting Pydantic versions and langchain-core\n",
    "!pip uninstall -y pydantic pydantic-core\n",
    "!pip uninstall -y langchain-core langchain-community langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain\n",
      "  Downloading langchain-0.3.27-py3-none-any.whl.metadata (7.8 kB)\n",
      "Collecting langchain-core\n",
      "  Using cached langchain_core-0.3.72-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting langchain-text-splitters<1.0.0,>=0.3.9 (from langchain)\n",
      "  Downloading langchain_text_splitters-0.3.9-py3-none-any.whl.metadata (1.9 kB)\n",
      "Requirement already satisfied: langsmith>=0.1.17 in c:\\users\\ch939\\anaconda3\\lib\\site-packages (from langchain) (0.4.8)\n",
      "Collecting pydantic<3.0.0,>=2.7.4 (from langchain)\n",
      "  Using cached pydantic-2.11.7-py3-none-any.whl.metadata (67 kB)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\ch939\\anaconda3\\lib\\site-packages (from langchain) (2.0.30)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\ch939\\anaconda3\\lib\\site-packages (from langchain) (2.32.2)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\ch939\\anaconda3\\lib\\site-packages (from langchain) (6.0.1)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in c:\\users\\ch939\\anaconda3\\lib\\site-packages (from langchain-core) (8.2.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\ch939\\anaconda3\\lib\\site-packages (from langchain-core) (1.33)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in c:\\users\\ch939\\anaconda3\\lib\\site-packages (from langchain-core) (4.14.1)\n",
      "Requirement already satisfied: packaging>=23.2 in c:\\users\\ch939\\anaconda3\\lib\\site-packages (from langchain-core) (23.2)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\ch939\\anaconda3\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core) (2.1)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\ch939\\anaconda3\\lib\\site-packages (from langsmith>=0.1.17->langchain) (0.27.0)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\ch939\\anaconda3\\lib\\site-packages (from langsmith>=0.1.17->langchain) (3.11.1)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\users\\ch939\\anaconda3\\lib\\site-packages (from langsmith>=0.1.17->langchain) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in c:\\users\\ch939\\anaconda3\\lib\\site-packages (from langsmith>=0.1.17->langchain) (0.23.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\ch939\\anaconda3\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.6.0)\n",
      "Collecting pydantic-core==2.33.2 (from pydantic<3.0.0,>=2.7.4->langchain)\n",
      "  Using cached pydantic_core-2.33.2-cp312-cp312-win_amd64.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\ch939\\anaconda3\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\ch939\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\ch939\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\ch939\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\ch939\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain) (2025.4.26)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\ch939\\anaconda3\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.1)\n",
      "Requirement already satisfied: anyio in c:\\users\\ch939\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (4.2.0)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\ch939\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (1.0.2)\n",
      "Requirement already satisfied: sniffio in c:\\users\\ch939\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (1.3.0)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\ch939\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (0.14.0)\n",
      "Downloading langchain-0.3.27-py3-none-any.whl (1.0 MB)\n",
      "   ---------------------------------------- 0.0/1.0 MB ? eta -:--:--\n",
      "   ---------- ----------------------------- 0.3/1.0 MB ? eta -:--:--\n",
      "   -------------------- ------------------- 0.5/1.0 MB 1.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.0/1.0 MB 2.1 MB/s eta 0:00:00\n",
      "Using cached langchain_core-0.3.72-py3-none-any.whl (442 kB)\n",
      "Downloading langchain_text_splitters-0.3.9-py3-none-any.whl (33 kB)\n",
      "Using cached pydantic-2.11.7-py3-none-any.whl (444 kB)\n",
      "Using cached pydantic_core-2.33.2-cp312-cp312-win_amd64.whl (2.0 MB)\n",
      "Installing collected packages: pydantic-core, pydantic, langchain-core, langchain-text-splitters, langchain\n",
      "Successfully installed langchain-0.3.27 langchain-core-0.3.72 langchain-text-splitters-0.3.9 pydantic-2.11.7 pydantic-core-2.33.2\n"
     ]
    }
   ],
   "source": [
    "# Install the latest langchain and langchain-core (which will pull compatible Pydantic V2):\n",
    "!pip install -U langchain langchain-core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5.3\n"
     ]
    }
   ],
   "source": [
    "import pydantic\n",
    "print(pydantic.VERSION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain-community\n",
      "  Downloading langchain_community-0.3.27-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.66 in c:\\users\\ch939\\anaconda3\\envs\\my_lcel_env\\lib\\site-packages (from langchain-community) (0.3.72)\n",
      "Requirement already satisfied: langchain<1.0.0,>=0.3.26 in c:\\users\\ch939\\anaconda3\\envs\\my_lcel_env\\lib\\site-packages (from langchain-community) (0.3.27)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\ch939\\anaconda3\\envs\\my_lcel_env\\lib\\site-packages (from langchain-community) (2.0.41)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\ch939\\anaconda3\\envs\\my_lcel_env\\lib\\site-packages (from langchain-community) (2.32.4)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\ch939\\anaconda3\\envs\\my_lcel_env\\lib\\site-packages (from langchain-community) (6.0.2)\n",
      "Collecting aiohttp<4.0.0,>=3.8.3 (from langchain-community)\n",
      "  Downloading aiohttp-3.12.14-cp311-cp311-win_amd64.whl.metadata (7.9 kB)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in c:\\users\\ch939\\anaconda3\\envs\\my_lcel_env\\lib\\site-packages (from langchain-community) (9.1.2)\n",
      "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain-community)\n",
      "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain-community)\n",
      "  Downloading pydantic_settings-2.10.1-py3-none-any.whl.metadata (3.4 kB)\n",
      "Requirement already satisfied: langsmith>=0.1.125 in c:\\users\\ch939\\anaconda3\\envs\\my_lcel_env\\lib\\site-packages (from langchain-community) (0.4.8)\n",
      "Collecting httpx-sse<1.0.0,>=0.4.0 (from langchain-community)\n",
      "  Downloading httpx_sse-0.4.1-py3-none-any.whl.metadata (9.4 kB)\n",
      "Collecting numpy>=1.26.2 (from langchain-community)\n",
      "  Downloading numpy-2.3.2-cp311-cp311-win_amd64.whl.metadata (60 kB)\n",
      "Collecting aiohappyeyeballs>=2.5.0 (from aiohttp<4.0.0,>=3.8.3->langchain-community)\n",
      "  Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting aiosignal>=1.4.0 (from aiohttp<4.0.0,>=3.8.3->langchain-community)\n",
      "  Downloading aiosignal-1.4.0-py3-none-any.whl.metadata (3.7 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\ch939\\anaconda3\\envs\\my_lcel_env\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.3.0)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp<4.0.0,>=3.8.3->langchain-community)\n",
      "  Downloading frozenlist-1.7.0-cp311-cp311-win_amd64.whl.metadata (19 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp<4.0.0,>=3.8.3->langchain-community)\n",
      "  Downloading multidict-6.6.3-cp311-cp311-win_amd64.whl.metadata (5.4 kB)\n",
      "Collecting propcache>=0.2.0 (from aiohttp<4.0.0,>=3.8.3->langchain-community)\n",
      "  Downloading propcache-0.3.2-cp311-cp311-win_amd64.whl.metadata (12 kB)\n",
      "Collecting yarl<2.0,>=1.17.0 (from aiohttp<4.0.0,>=3.8.3->langchain-community)\n",
      "  Downloading yarl-1.20.1-cp311-cp311-win_amd64.whl.metadata (76 kB)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
      "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
      "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
      "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.9 in c:\\users\\ch939\\anaconda3\\envs\\my_lcel_env\\lib\\site-packages (from langchain<1.0.0,>=0.3.26->langchain-community) (0.3.9)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\users\\ch939\\anaconda3\\envs\\my_lcel_env\\lib\\site-packages (from langchain<1.0.0,>=0.3.26->langchain-community) (2.11.7)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\ch939\\anaconda3\\envs\\my_lcel_env\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.66->langchain-community) (1.33)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in c:\\users\\ch939\\anaconda3\\envs\\my_lcel_env\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.66->langchain-community) (4.14.1)\n",
      "Requirement already satisfied: packaging>=23.2 in c:\\users\\ch939\\anaconda3\\envs\\my_lcel_env\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.66->langchain-community) (25.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\ch939\\anaconda3\\envs\\my_lcel_env\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.66->langchain-community) (3.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\ch939\\anaconda3\\envs\\my_lcel_env\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.26->langchain-community) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\ch939\\anaconda3\\envs\\my_lcel_env\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.26->langchain-community) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\ch939\\anaconda3\\envs\\my_lcel_env\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.26->langchain-community) (0.4.1)\n",
      "Collecting python-dotenv>=0.21.0 (from pydantic-settings<3.0.0,>=2.4.0->langchain-community)\n",
      "  Downloading python_dotenv-1.1.1-py3-none-any.whl.metadata (24 kB)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\ch939\\anaconda3\\envs\\my_lcel_env\\lib\\site-packages (from requests<3,>=2->langchain-community) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\ch939\\anaconda3\\envs\\my_lcel_env\\lib\\site-packages (from requests<3,>=2->langchain-community) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\ch939\\anaconda3\\envs\\my_lcel_env\\lib\\site-packages (from requests<3,>=2->langchain-community) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\ch939\\anaconda3\\envs\\my_lcel_env\\lib\\site-packages (from requests<3,>=2->langchain-community) (2025.7.14)\n",
      "Requirement already satisfied: greenlet>=1 in c:\\users\\ch939\\anaconda3\\envs\\my_lcel_env\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain-community) (3.2.3)\n",
      "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
      "  Downloading mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\ch939\\anaconda3\\envs\\my_lcel_env\\lib\\site-packages (from langsmith>=0.1.125->langchain-community) (0.28.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\ch939\\anaconda3\\envs\\my_lcel_env\\lib\\site-packages (from langsmith>=0.1.125->langchain-community) (3.11.1)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\users\\ch939\\anaconda3\\envs\\my_lcel_env\\lib\\site-packages (from langsmith>=0.1.125->langchain-community) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in c:\\users\\ch939\\anaconda3\\envs\\my_lcel_env\\lib\\site-packages (from langsmith>=0.1.125->langchain-community) (0.23.0)\n",
      "Requirement already satisfied: anyio in c:\\users\\ch939\\anaconda3\\envs\\my_lcel_env\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith>=0.1.125->langchain-community) (4.9.0)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\ch939\\anaconda3\\envs\\my_lcel_env\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith>=0.1.125->langchain-community) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\ch939\\anaconda3\\envs\\my_lcel_env\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.1.125->langchain-community) (0.16.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\ch939\\anaconda3\\envs\\my_lcel_env\\lib\\site-packages (from anyio->httpx<1,>=0.23.0->langsmith>=0.1.125->langchain-community) (1.3.1)\n",
      "Downloading langchain_community-0.3.27-py3-none-any.whl (2.5 MB)\n",
      "   ---------------------------------------- 0.0/2.5 MB ? eta -:--:--\n",
      "   -------- ------------------------------- 0.5/2.5 MB 4.2 MB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 1.0/2.5 MB 3.1 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 1.6/2.5 MB 2.7 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 2.1/2.5 MB 2.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.5/2.5 MB 2.7 MB/s eta 0:00:00\n",
      "Downloading aiohttp-3.12.14-cp311-cp311-win_amd64.whl (452 kB)\n",
      "Downloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
      "Downloading httpx_sse-0.4.1-py3-none-any.whl (8.1 kB)\n",
      "Downloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
      "Downloading multidict-6.6.3-cp311-cp311-win_amd64.whl (45 kB)\n",
      "Downloading pydantic_settings-2.10.1-py3-none-any.whl (45 kB)\n",
      "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Downloading yarl-1.20.1-cp311-cp311-win_amd64.whl (86 kB)\n",
      "Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\n",
      "Downloading aiosignal-1.4.0-py3-none-any.whl (7.5 kB)\n",
      "Downloading frozenlist-1.7.0-cp311-cp311-win_amd64.whl (44 kB)\n",
      "Downloading mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
      "Downloading numpy-2.3.2-cp311-cp311-win_amd64.whl (13.1 MB)\n",
      "   ---------------------------------------- 0.0/13.1 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.5/13.1 MB 3.4 MB/s eta 0:00:04\n",
      "   ---- ----------------------------------- 1.3/13.1 MB 3.7 MB/s eta 0:00:04\n",
      "   ------ --------------------------------- 2.1/13.1 MB 3.8 MB/s eta 0:00:03\n",
      "   ---------- ----------------------------- 3.4/13.1 MB 4.6 MB/s eta 0:00:03\n",
      "   ------------- -------------------------- 4.5/13.1 MB 4.8 MB/s eta 0:00:02\n",
      "   ------------------ --------------------- 6.0/13.1 MB 5.1 MB/s eta 0:00:02\n",
      "   --------------------- ------------------ 7.1/13.1 MB 5.1 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 8.1/13.1 MB 5.1 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 9.4/13.1 MB 5.2 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 10.5/13.1 MB 5.4 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 11.8/13.1 MB 5.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  12.8/13.1 MB 5.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 13.1/13.1 MB 5.2 MB/s eta 0:00:00\n",
      "Downloading propcache-0.3.2-cp311-cp311-win_amd64.whl (41 kB)\n",
      "Downloading python_dotenv-1.1.1-py3-none-any.whl (20 kB)\n",
      "Installing collected packages: python-dotenv, propcache, numpy, mypy-extensions, multidict, marshmallow, httpx-sse, frozenlist, aiohappyeyeballs, yarl, typing-inspect, aiosignal, pydantic-settings, dataclasses-json, aiohttp, langchain-community\n",
      "\n",
      "   ----- ----------------------------------  2/16 [numpy]\n",
      "   ----- ----------------------------------  2/16 [numpy]\n",
      "   ----- ----------------------------------  2/16 [numpy]\n",
      "   ----- ----------------------------------  2/16 [numpy]\n",
      "   ----- ----------------------------------  2/16 [numpy]\n",
      "   ----- ----------------------------------  2/16 [numpy]\n",
      "   ----- ----------------------------------  2/16 [numpy]\n",
      "   ----- ----------------------------------  2/16 [numpy]\n",
      "   ----- ----------------------------------  2/16 [numpy]\n",
      "   ----- ----------------------------------  2/16 [numpy]\n",
      "   ----- ----------------------------------  2/16 [numpy]\n",
      "   --------------- ------------------------  6/16 [httpx-sse]\n",
      "   -------------------------------- ------- 13/16 [dataclasses-json]\n",
      "   ----------------------------------- ---- 14/16 [aiohttp]\n",
      "   ------------------------------------- -- 15/16 [langchain-community]\n",
      "   ------------------------------------- -- 15/16 [langchain-community]\n",
      "   ------------------------------------- -- 15/16 [langchain-community]\n",
      "   ------------------------------------- -- 15/16 [langchain-community]\n",
      "   ------------------------------------- -- 15/16 [langchain-community]\n",
      "   ------------------------------------- -- 15/16 [langchain-community]\n",
      "   ------------------------------------- -- 15/16 [langchain-community]\n",
      "   ------------------------------------- -- 15/16 [langchain-community]\n",
      "   ------------------------------------- -- 15/16 [langchain-community]\n",
      "   ------------------------------------- -- 15/16 [langchain-community]\n",
      "   ------------------------------------- -- 15/16 [langchain-community]\n",
      "   ------------------------------------- -- 15/16 [langchain-community]\n",
      "   ------------------------------------- -- 15/16 [langchain-community]\n",
      "   ---------------------------------------- 16/16 [langchain-community]\n",
      "\n",
      "Successfully installed aiohappyeyeballs-2.6.1 aiohttp-3.12.14 aiosignal-1.4.0 dataclasses-json-0.6.7 frozenlist-1.7.0 httpx-sse-0.4.1 langchain-community-0.3.27 marshmallow-3.26.1 multidict-6.6.3 mypy-extensions-1.1.0 numpy-2.3.2 propcache-0.3.2 pydantic-settings-2.10.1 python-dotenv-1.1.1 typing-inspect-0.9.0 yarl-1.20.1\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain-community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User prompt: 'What is the capital of Germany?'\n",
      "Model answer: \n",
      "The capital of Germany is Berlin.\n"
     ]
    }
   ],
   "source": [
    "# Example: Using LCEL to reproduce a \"Basic Prompting\" scenario\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_community.chat_models import ChatOllama \n",
    "\n",
    "# 2. Define the prompt\n",
    "prompt = PromptTemplate.from_template(\n",
    "    \"What is the capital of {topic}?\"\n",
    ")\n",
    "\n",
    "# 3. Define the model\n",
    "model = ChatOllama(model = \"llama2\")  # Using Ollama , string, not list\n",
    "\n",
    "# 4. Chain the components together using LCEL\n",
    "chain = (\n",
    "    # LCEL syntax: use the pipe operator | to connect each step\n",
    "    {\"topic\": RunnablePassthrough()}  # Accept user input\n",
    "    | prompt                          # Transform it into a prompt message\n",
    "    | model                           # Call the model\n",
    "    | StrOutputParser()               # Parse the output as a string\n",
    ")\n",
    "\n",
    "# 5. Execute\n",
    "result = chain.invoke(\"Germany\")\n",
    "print(\"User prompt: 'What is the capital of Germany?'\")\n",
    "print(\"Model answer:\", result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Submission Requirements**  \n",
    "1. Complete all tasks.  \n",
    "2. Include screenshots of key outputs (e.g., model responses, agent computation results).\n",
    "\n",
    "- Advance WorkÔºöIntegrate the Ollama and Langchain tasks into **Gradio Web UI**, which will be useful for building Proxy AI-Agent interface translation with front-end, and demonstrate your work.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
