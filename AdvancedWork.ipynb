{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aefae9cc-1b78-4565-96aa-be7137530e14",
   "metadata": {},
   "source": [
    "# Advanced Work"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "366a8bbf-7ab9-4845-b50e-424ed88d4b12",
   "metadata": {},
   "source": [
    "by Samuel Huang"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8e700f1-8023-4683-8156-c62490e470ef",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Integrate the Ollama and Langchain tasks into Gradio Web UI, which will be useful for building Proxy AI-Agent interface translation with front-end, and demonstrate your work"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8896fa97-0daa-4526-814e-970f22efd5a4",
   "metadata": {},
   "source": [
    "## 0. Prerequisites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e158f98b-7923-495e-a9c4-e64a8a2f8771",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.12.3 | packaged by conda-forge | (main, Apr 15 2024, 18:20:11) [MSC v.1938 64 bit (AMD64)]\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2c6e013c-7e2f-43a2-a568-609d5261af87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain-community\n",
      "  Using cached langchain_community-0.3.27-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: langchain_core in c:\\users\\ch939\\anaconda3\\lib\\site-packages (0.3.72)\n",
      "Collecting gradio\n",
      "  Using cached gradio-5.38.2-py3-none-any.whl.metadata (16 kB)\n",
      "Requirement already satisfied: langchain<1.0.0,>=0.3.26 in c:\\users\\ch939\\anaconda3\\lib\\site-packages (from langchain-community) (0.3.27)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\ch939\\anaconda3\\lib\\site-packages (from langchain-community) (2.0.30)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\ch939\\anaconda3\\lib\\site-packages (from langchain-community) (2.32.2)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\ch939\\anaconda3\\lib\\site-packages (from langchain-community) (6.0.1)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\ch939\\anaconda3\\lib\\site-packages (from langchain-community) (3.9.5)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in c:\\users\\ch939\\anaconda3\\lib\\site-packages (from langchain-community) (8.2.2)\n",
      "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain-community)\n",
      "  Using cached dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain-community)\n",
      "  Using cached pydantic_settings-2.10.1-py3-none-any.whl.metadata (3.4 kB)\n",
      "Requirement already satisfied: langsmith>=0.1.125 in c:\\users\\ch939\\anaconda3\\lib\\site-packages (from langchain-community) (0.4.8)\n",
      "Collecting httpx-sse<1.0.0,>=0.4.0 (from langchain-community)\n",
      "  Using cached httpx_sse-0.4.1-py3-none-any.whl.metadata (9.4 kB)\n",
      "Requirement already satisfied: numpy>=1.26.2 in c:\\users\\ch939\\anaconda3\\lib\\site-packages (from langchain-community) (1.26.4)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\ch939\\anaconda3\\lib\\site-packages (from langchain_core) (1.33)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in c:\\users\\ch939\\anaconda3\\lib\\site-packages (from langchain_core) (4.14.1)\n",
      "Requirement already satisfied: packaging>=23.2 in c:\\users\\ch939\\anaconda3\\lib\\site-packages (from langchain_core) (23.2)\n",
      "Requirement already satisfied: pydantic>=2.7.4 in c:\\users\\ch939\\anaconda3\\lib\\site-packages (from langchain_core) (2.11.7)\n",
      "Collecting aiofiles<25.0,>=22.0 (from gradio)\n",
      "  Using cached aiofiles-24.1.0-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: anyio<5.0,>=3.0 in c:\\users\\ch939\\anaconda3\\lib\\site-packages (from gradio) (4.2.0)\n",
      "Collecting brotli>=1.1.0 (from gradio)\n",
      "  Downloading Brotli-1.1.0-cp312-cp312-win_amd64.whl.metadata (5.6 kB)\n",
      "Collecting fastapi<1.0,>=0.115.2 (from gradio)\n",
      "  Using cached fastapi-0.116.1-py3-none-any.whl.metadata (28 kB)\n",
      "Collecting ffmpy (from gradio)\n",
      "  Using cached ffmpy-0.6.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting gradio-client==1.11.0 (from gradio)\n",
      "  Using cached gradio_client-1.11.0-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting groovy~=0.1 (from gradio)\n",
      "  Using cached groovy-0.1.2-py3-none-any.whl.metadata (6.1 kB)\n",
      "Requirement already satisfied: httpx<1.0,>=0.24.1 in c:\\users\\ch939\\anaconda3\\lib\\site-packages (from gradio) (0.27.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.28.1 in c:\\users\\ch939\\anaconda3\\lib\\site-packages (from gradio) (0.31.2)\n",
      "Requirement already satisfied: jinja2<4.0 in c:\\users\\ch939\\anaconda3\\lib\\site-packages (from gradio) (3.1.4)\n",
      "Requirement already satisfied: markupsafe<4.0,>=2.0 in c:\\users\\ch939\\anaconda3\\lib\\site-packages (from gradio) (2.1.3)\n",
      "Requirement already satisfied: orjson~=3.0 in c:\\users\\ch939\\anaconda3\\lib\\site-packages (from gradio) (3.11.1)\n",
      "Requirement already satisfied: pandas<3.0,>=1.0 in c:\\users\\ch939\\anaconda3\\lib\\site-packages (from gradio) (2.2.2)\n",
      "Requirement already satisfied: pillow<12.0,>=8.0 in c:\\users\\ch939\\anaconda3\\lib\\site-packages (from gradio) (10.3.0)\n",
      "Collecting pydub (from gradio)\n",
      "  Using cached pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting python-multipart>=0.0.18 (from gradio)\n",
      "  Using cached python_multipart-0.0.20-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting ruff>=0.9.3 (from gradio)\n",
      "  Using cached ruff-0.12.5-py3-none-win_amd64.whl.metadata (26 kB)\n",
      "Collecting safehttpx<0.2.0,>=0.1.6 (from gradio)\n",
      "  Using cached safehttpx-0.1.6-py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting semantic-version~=2.0 (from gradio)\n",
      "  Using cached semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\n",
      "Collecting starlette<1.0,>=0.40.0 (from gradio)\n",
      "  Using cached starlette-0.47.2-py3-none-any.whl.metadata (6.2 kB)\n",
      "Collecting tomlkit<0.14.0,>=0.12.0 (from gradio)\n",
      "  Using cached tomlkit-0.13.3-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting typer<1.0,>=0.12 (from gradio)\n",
      "  Using cached typer-0.16.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting uvicorn>=0.14.0 (from gradio)\n",
      "  Using cached uvicorn-0.35.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Requirement already satisfied: fsspec in c:\\users\\ch939\\anaconda3\\lib\\site-packages (from gradio-client==1.11.0->gradio) (2024.3.1)\n",
      "Collecting websockets<16.0,>=10.0 (from gradio-client==1.11.0->gradio)\n",
      "  Downloading websockets-15.0.1-cp312-cp312-win_amd64.whl.metadata (7.0 kB)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\ch939\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\ch939\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (24.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\ch939\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\ch939\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\ch939\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.9.3)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\ch939\\anaconda3\\lib\\site-packages (from anyio<5.0,>=3.0->gradio) (3.7)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\ch939\\anaconda3\\lib\\site-packages (from anyio<5.0,>=3.0->gradio) (1.3.0)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
      "  Using cached marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
      "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
      "  Using cached typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: certifi in c:\\users\\ch939\\anaconda3\\lib\\site-packages (from httpx<1.0,>=0.24.1->gradio) (2025.4.26)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\ch939\\anaconda3\\lib\\site-packages (from httpx<1.0,>=0.24.1->gradio) (1.0.2)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\ch939\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx<1.0,>=0.24.1->gradio) (0.14.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\ch939\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.28.1->gradio) (3.13.1)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in c:\\users\\ch939\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.28.1->gradio) (4.66.4)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\ch939\\anaconda3\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain_core) (2.1)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.9 in c:\\users\\ch939\\anaconda3\\lib\\site-packages (from langchain<1.0.0,>=0.3.26->langchain-community) (0.3.9)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\users\\ch939\\anaconda3\\lib\\site-packages (from langsmith>=0.1.125->langchain-community) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in c:\\users\\ch939\\anaconda3\\lib\\site-packages (from langsmith>=0.1.125->langchain-community) (0.23.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\ch939\\anaconda3\\lib\\site-packages (from pandas<3.0,>=1.0->gradio) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\ch939\\anaconda3\\lib\\site-packages (from pandas<3.0,>=1.0->gradio) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\ch939\\anaconda3\\lib\\site-packages (from pandas<3.0,>=1.0->gradio) (2023.3)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\ch939\\anaconda3\\lib\\site-packages (from pydantic>=2.7.4->langchain_core) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\ch939\\anaconda3\\lib\\site-packages (from pydantic>=2.7.4->langchain_core) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\ch939\\anaconda3\\lib\\site-packages (from pydantic>=2.7.4->langchain_core) (0.4.1)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in c:\\users\\ch939\\anaconda3\\lib\\site-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community) (0.21.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\ch939\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain-community) (2.0.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\ch939\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain-community) (2.2.2)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\ch939\\anaconda3\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain-community) (3.0.1)\n",
      "Requirement already satisfied: click>=8.0.0 in c:\\users\\ch939\\anaconda3\\lib\\site-packages (from typer<1.0,>=0.12->gradio) (8.1.7)\n",
      "Collecting shellingham>=1.3.0 (from typer<1.0,>=0.12->gradio)\n",
      "  Using cached shellingham-1.5.4-py2.py3-none-any.whl.metadata (3.5 kB)\n",
      "Requirement already satisfied: rich>=10.11.0 in c:\\users\\ch939\\anaconda3\\lib\\site-packages (from typer<1.0,>=0.12->gradio) (13.3.5)\n",
      "Requirement already satisfied: colorama in c:\\users\\ch939\\anaconda3\\lib\\site-packages (from click>=8.0.0->typer<1.0,>=0.12->gradio) (0.4.6)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\ch939\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.16.0)\n",
      "Requirement already satisfied: markdown-it-py<3.0.0,>=2.2.0 in c:\\users\\ch939\\anaconda3\\lib\\site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\ch939\\anaconda3\\lib\\site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.15.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\ch939\\anaconda3\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.0.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\ch939\\anaconda3\\lib\\site-packages (from markdown-it-py<3.0.0,>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.0)\n",
      "Using cached langchain_community-0.3.27-py3-none-any.whl (2.5 MB)\n",
      "Using cached gradio-5.38.2-py3-none-any.whl (59.5 MB)\n",
      "Using cached gradio_client-1.11.0-py3-none-any.whl (324 kB)\n",
      "Using cached aiofiles-24.1.0-py3-none-any.whl (15 kB)\n",
      "Downloading Brotli-1.1.0-cp312-cp312-win_amd64.whl (357 kB)\n",
      "Using cached dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
      "Using cached fastapi-0.116.1-py3-none-any.whl (95 kB)\n",
      "Using cached groovy-0.1.2-py3-none-any.whl (14 kB)\n",
      "Using cached httpx_sse-0.4.1-py3-none-any.whl (8.1 kB)\n",
      "Using cached pydantic_settings-2.10.1-py3-none-any.whl (45 kB)\n",
      "Using cached python_multipart-0.0.20-py3-none-any.whl (24 kB)\n",
      "Using cached ruff-0.12.5-py3-none-win_amd64.whl (12.9 MB)\n",
      "Using cached safehttpx-0.1.6-py3-none-any.whl (8.7 kB)\n",
      "Using cached semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
      "Using cached starlette-0.47.2-py3-none-any.whl (72 kB)\n",
      "Using cached tomlkit-0.13.3-py3-none-any.whl (38 kB)\n",
      "Using cached typer-0.16.0-py3-none-any.whl (46 kB)\n",
      "Using cached uvicorn-0.35.0-py3-none-any.whl (66 kB)\n",
      "Using cached ffmpy-0.6.1-py3-none-any.whl (5.5 kB)\n",
      "Using cached pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
      "Using cached marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
      "Using cached shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
      "Using cached typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Downloading websockets-15.0.1-cp312-cp312-win_amd64.whl (176 kB)\n",
      "Installing collected packages: pydub, brotli, websockets, typing-inspect, tomlkit, shellingham, semantic-version, ruff, python-multipart, marshmallow, httpx-sse, groovy, ffmpy, aiofiles, uvicorn, starlette, dataclasses-json, typer, safehttpx, pydantic-settings, gradio-client, fastapi, gradio, langchain-community\n",
      "  Attempting uninstall: brotli\n",
      "    Found existing installation: Brotli 1.0.9\n",
      "    Uninstalling Brotli-1.0.9:\n",
      "      Successfully uninstalled Brotli-1.0.9\n",
      "  Attempting uninstall: tomlkit\n",
      "    Found existing installation: tomlkit 0.11.1\n",
      "    Uninstalling tomlkit-0.11.1:\n",
      "      Successfully uninstalled tomlkit-0.11.1\n",
      "Successfully installed aiofiles-24.1.0 brotli-1.1.0 dataclasses-json-0.6.7 fastapi-0.116.1 ffmpy-0.6.1 gradio-5.38.2 gradio-client-1.11.0 groovy-0.1.2 httpx-sse-0.4.1 langchain-community-0.3.27 marshmallow-3.26.1 pydantic-settings-2.10.1 pydub-0.25.1 python-multipart-0.0.20 ruff-0.12.5 safehttpx-0.1.6 semantic-version-2.10.0 shellingham-1.5.4 starlette-0.47.2 tomlkit-0.13.3 typer-0.16.0 typing-inspect-0.9.0 uvicorn-0.35.0 websockets-15.0.1\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain-community langchain_core gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4747b1c0-c623-4dec-b68e-c66172ef225b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME             ID              SIZE      MODIFIED     \n",
      "llama2:latest    78e26419b446    3.8 GB    19 hours ago    \n"
     ]
    }
   ],
   "source": [
    "!ollama list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eb92902-5c71-436b-b01c-f8c7e094326c",
   "metadata": {},
   "source": [
    "Run ollama run llama2 from the Anaconda command line to download and launch the llama2 model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f7ec50b-5fa7-48fe-9f1c-61780e9d2f6d",
   "metadata": {},
   "source": [
    "## 1. Pull a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1a1ef2f1-6c56-443c-abad-9ba248cb296e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest â ‹ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest â ™ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest â ¹ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest \u001b[K\n",
      "pulling 6a0746a1ec1a: 100% â–•â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–� 4.7 GB                         \u001b[K\n",
      "pulling 4fa551d4f938: 100% â–•â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–�  12 KB                         \u001b[K\n",
      "pulling 8ab4849b038c: 100% â–•â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–�  254 B                         \u001b[K\n",
      "pulling 577073ffcc6c: 100% â–•â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–�  110 B                         \u001b[K\n",
      "pulling 3f8eb4da87fa: 100% â–•â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–�  485 B                         \u001b[K\n",
      "verifying sha256 digest \u001b[K\n",
      "writing manifest \u001b[K\n",
      "success \u001b[K\u001b[?25h\u001b[?2026l\n"
     ]
    }
   ],
   "source": [
    "!ollama pull llama3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeb2b27c-26e9-4091-94ad-39b0a9749d71",
   "metadata": {},
   "source": [
    "## 2. Create the LangChain Component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "68da6d08-ffe2-4132-b8e3-cd1b313505ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original:\n",
      "Hello, how are you today? This is a demonstration of an AI agent.\n",
      "\n",
      "Translated:\n",
      "Bonjour ! Comment allez-vous aujourd'hui ? Voici une démonstration d'un agent IA.\n",
      "\n",
      "(Note: The translation is provided below, along with some explanations:\n",
      "\n",
      "* \"Hello\" is translated to the more formal \"Bonjour\" in French.\n",
      "* \"how are you today?\" remains unchanged, as it's a common phrase used to greet someone and inquire about their well-being.\n",
      "* \"This is a demonstration of an AI agent.\" becomes \"Voici une démonstration d'un agent IA\", where \"IA\" stands for \"Intelligence Artificielle\", the French term for Artificial Intelligence.\n"
     ]
    }
   ],
   "source": [
    "# langchain_agent.py\n",
    "\n",
    "from langchain_community.llms import Ollama\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "\n",
    "class TranslationAgent:\n",
    "    \"\"\"\n",
    "    A simple translation agent that uses a local LLM (via Ollama) and LangChain\n",
    "    to translate English text into French.\n",
    "    \"\"\"\n",
    "    def __init__(self, model_name: str = \"llama3\"):\n",
    "        # Initialize the LLM\n",
    "        self.llm = Ollama(model=model_name)\n",
    "\n",
    "        # Define the translation prompt\n",
    "        self.prompt = ChatPromptTemplate.from_messages([\n",
    "            (\"system\", \"You are a helpful AI assistant specialized in language translation. \"\n",
    "                       \"Translate the following text from English to French.\"),\n",
    "            (\"user\", \"{text}\")\n",
    "        ])\n",
    "\n",
    "        # Compose the chain: prompt → LLM → output parser\n",
    "        self.chain = self.prompt | self.llm | StrOutputParser()\n",
    "\n",
    "    def translate(self, text: str) -> str:\n",
    "        \"\"\"\n",
    "        Translates the given English text to French using the Ollama LLM.\n",
    "\n",
    "        Args:\n",
    "            text (str): English text to be translated.\n",
    "\n",
    "        Returns:\n",
    "            str: Translated French text, or error message.\n",
    "        \"\"\"\n",
    "        if not text.strip():\n",
    "            return \"Input text is empty.\"\n",
    "\n",
    "        try:\n",
    "            response = self.chain.invoke({\"text\": text})\n",
    "            return response.strip()\n",
    "        except Exception as e:\n",
    "            return f\"Error during translation: {e}\"\n",
    "\n",
    "\n",
    "# Example usage for testing\n",
    "if __name__ == \"__main__\":\n",
    "    agent = TranslationAgent()\n",
    "    english_text = \"Hello, how are you today? This is a demonstration of an AI agent.\"\n",
    "    french_translation = agent.translate(english_text)\n",
    "\n",
    "    print(\"Original:\")\n",
    "    print(english_text)\n",
    "    print(\"\\nTranslated:\")\n",
    "    print(french_translation)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc7d93c3-ab3b-4f8f-b96f-6b64b4825aae",
   "metadata": {},
   "source": [
    "## 3. Create the Gradio Web UI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d64d8841-2fc1-443b-bad6-cae9130bdf98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain-ollama\n",
      "  Downloading langchain_ollama-0.3.6-py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting ollama<1.0.0,>=0.5.1 (from langchain-ollama)\n",
      "  Downloading ollama-0.5.1-py3-none-any.whl.metadata (4.3 kB)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.70 in c:\\users\\ch939\\anaconda3\\lib\\site-packages (from langchain-ollama) (0.3.72)\n",
      "Requirement already satisfied: langsmith>=0.3.45 in c:\\users\\ch939\\anaconda3\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.70->langchain-ollama) (0.4.8)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in c:\\users\\ch939\\anaconda3\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.70->langchain-ollama) (8.2.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\ch939\\anaconda3\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.70->langchain-ollama) (1.33)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\ch939\\anaconda3\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.70->langchain-ollama) (6.0.1)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in c:\\users\\ch939\\anaconda3\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.70->langchain-ollama) (4.14.1)\n",
      "Requirement already satisfied: packaging>=23.2 in c:\\users\\ch939\\anaconda3\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.70->langchain-ollama) (23.2)\n",
      "Requirement already satisfied: pydantic>=2.7.4 in c:\\users\\ch939\\anaconda3\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.70->langchain-ollama) (2.11.7)\n",
      "Requirement already satisfied: httpx>=0.27 in c:\\users\\ch939\\anaconda3\\lib\\site-packages (from ollama<1.0.0,>=0.5.1->langchain-ollama) (0.27.0)\n",
      "Requirement already satisfied: anyio in c:\\users\\ch939\\anaconda3\\lib\\site-packages (from httpx>=0.27->ollama<1.0.0,>=0.5.1->langchain-ollama) (4.2.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\ch939\\anaconda3\\lib\\site-packages (from httpx>=0.27->ollama<1.0.0,>=0.5.1->langchain-ollama) (2025.4.26)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\ch939\\anaconda3\\lib\\site-packages (from httpx>=0.27->ollama<1.0.0,>=0.5.1->langchain-ollama) (1.0.2)\n",
      "Requirement already satisfied: idna in c:\\users\\ch939\\anaconda3\\lib\\site-packages (from httpx>=0.27->ollama<1.0.0,>=0.5.1->langchain-ollama) (3.7)\n",
      "Requirement already satisfied: sniffio in c:\\users\\ch939\\anaconda3\\lib\\site-packages (from httpx>=0.27->ollama<1.0.0,>=0.5.1->langchain-ollama) (1.3.0)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\ch939\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx>=0.27->ollama<1.0.0,>=0.5.1->langchain-ollama) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\ch939\\anaconda3\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.70->langchain-ollama) (2.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\ch939\\anaconda3\\lib\\site-packages (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.70->langchain-ollama) (3.11.1)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\ch939\\anaconda3\\lib\\site-packages (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.70->langchain-ollama) (2.32.2)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\users\\ch939\\anaconda3\\lib\\site-packages (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.70->langchain-ollama) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in c:\\users\\ch939\\anaconda3\\lib\\site-packages (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.70->langchain-ollama) (0.23.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\ch939\\anaconda3\\lib\\site-packages (from pydantic>=2.7.4->langchain-core<1.0.0,>=0.3.70->langchain-ollama) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\ch939\\anaconda3\\lib\\site-packages (from pydantic>=2.7.4->langchain-core<1.0.0,>=0.3.70->langchain-ollama) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\ch939\\anaconda3\\lib\\site-packages (from pydantic>=2.7.4->langchain-core<1.0.0,>=0.3.70->langchain-ollama) (0.4.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\ch939\\anaconda3\\lib\\site-packages (from requests<3,>=2->langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.70->langchain-ollama) (2.0.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\ch939\\anaconda3\\lib\\site-packages (from requests<3,>=2->langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.70->langchain-ollama) (2.2.2)\n",
      "Downloading langchain_ollama-0.3.6-py3-none-any.whl (24 kB)\n",
      "Downloading ollama-0.5.1-py3-none-any.whl (13 kB)\n",
      "Installing collected packages: ollama, langchain-ollama\n",
      "Successfully installed langchain-ollama-0.3.6 ollama-0.5.1\n"
     ]
    }
   ],
   "source": [
    "!pip install -U langchain-ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "cb213c02-5d44-42d4-bc12-f733853d0771",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ch939\\AppData\\Local\\Temp\\ipykernel_11680\\2079752146.py:18: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use :meth:`~RunnableSequence, e.g., `prompt | llm`` instead.\n",
      "  translation_chain = LLMChain(llm=llm, prompt=prompt)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Gradio app...\n",
      "Ensure the Ollama server is running and 'llama3' model is pulled.\n",
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "Could not create share link. Please check your internet connection or our status page: https://status.gradio.app.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# gradio_app.py\n",
    "\n",
    "import gradio as gr\n",
    "from langchain_ollama import ChatOllama\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "\n",
    "# Initialize the LLM from Ollama\n",
    "llm = ChatOllama(model=\"llama3\")  # Ensure 'llama3' model is pulled in Ollama\n",
    "\n",
    "# Create a prompt template for translation\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"input_text\"],\n",
    "    template=\"Translate the following English text to French:\\n\\n{input_text}\"\n",
    ")\n",
    "\n",
    "# Create a LangChain LLMChain using the prompt and the LLM\n",
    "translation_chain = LLMChain(llm=llm, prompt=prompt)\n",
    "\n",
    "def gradio_translate_interface(input_text):\n",
    "    \"\"\"\n",
    "    Gradio interface function to perform English to French translation.\n",
    "    \"\"\"\n",
    "    if not input_text.strip():\n",
    "        return \"Please enter text to translate.\"\n",
    "    \n",
    "    print(f\"Received input: {input_text}\")\n",
    "    translated_text = translation_chain.run({\"input_text\": input_text})\n",
    "    print(f\"Generated output: {translated_text}\")\n",
    "    return translated_text.strip()\n",
    "\n",
    "# Create the Gradio interface\n",
    "iface = gr.Interface(\n",
    "    fn=gradio_translate_interface,\n",
    "    inputs=gr.Textbox(lines=5, placeholder=\"Enter English text for translation...\", label=\"English Input\"),\n",
    "    outputs=gr.Textbox(lines=5, label=\"French Translation\"),\n",
    "    title=\"Proxy AI Translator (Ollama + LangChain + Gradio)\",\n",
    "    description=\"This app uses a local LLM (llama3 via Ollama) with LangChain to perform English to French translation.\"\n",
    ")\n",
    "\n",
    "# Launch the Gradio app\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"Starting Gradio app...\")\n",
    "    print(\"Ensure the Ollama server is running and 'llama3' model is pulled.\")\n",
    "    iface.launch(share=True)  # Set share=True to get a public URL (for sharing or testing)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c792926a-aa31-4b47-aeee-82dbbe889dc4",
   "metadata": {},
   "source": [
    "## 4. Running the Application"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d0dd28f-89b1-4457-9c70-68b5d821fdb4",
   "metadata": {},
   "source": [
    "__Ensure Ollama is running:__ Open your terminal and simply run ollama serve in the background, or ensure the Ollama desktop application is active."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "465c8383-7607-4198-8b20-aa6672dcc155",
   "metadata": {},
   "source": [
    "__Run the Gradio app:__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e4c8a16-5d21-4a8b-a1f6-8650f568a88c",
   "metadata": {},
   "source": [
    "python gradio_app.py"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
